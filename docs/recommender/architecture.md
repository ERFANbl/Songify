Thought for a second


# Song Representation & Multi-Label Regression System

This repository implements a **multimodal** system that fuses **song lyrics**, **audio features**, and **metadata** into a single joint embedding and predicts 18 continuous songâ€level labels. The architecture is endâ€‘toâ€‘end trainable (including the LLM) and may evolve over time.

---

## ðŸ“– Architecture Overview

```
[Start]
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Song Lyrics  â”‚   â”‚  Audio File   â”‚   â”‚   Metadata    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                   â”‚
       â–¼                 â–¼                   â–¼
[LLM Embedding]   [Extract Audio Features]   [Process Metadata]
   (1024â€‘d)             (22â€‘d)                 (~8â€‘d)
       â”‚                 â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
   [Fusion Layer]  (concatenate all three vectors)
                  â”‚
                  â–¼
   [MLP â€“ Feature Projection] (compact shared embedding)
                  â”‚
                  â–¼
[Encoder Network (Fully Connected Layers)]  
                  â”‚
                  â–¼
[Regression Head â†’ 18 continuous targets]
                  â”‚
                [End]
```

---

## ðŸ” Component Details

1. **Lyrics Encoder**

   * **Model**: `BAAI/bge-large-en-v1.5` (OpenAIâ€‘compatible embedding LLM)
   * **Input**: Raw song lyrics
   * **Output**: 1024â€‘dim semantic embedding (CLS token)

2. **Audio Feature Encoder**

   * **Input features (22â€‘dim)**:

     ```
     zcr_mean, rms_mean, centroid_mean, bw_mean, flat_mean,
     mfcc1_mean, mfcc2_mean, chroma_mean,
     zcr_std,  rms_std,  centroid_std,  bw_std,  flat_std,
     mfcc1_std, mfcc2_std, chroma_std,
     mfcc1_dmean, mfcc2_dmean,
     tempo, tempo_conf, beat_int_mean, beat_int_std
     ```
   * **Processing**: Small MLP (e.g., Linearâ†’ReLUâ†’Dropout)
   * **Output**: 22â€‘dim â†’ projected to match fusion space

3. **Metadata Encoder**

   * **Fields**:

     * `genre` (7 categories: country, jazz, blues, hip hop, pop, reggae, rock)
     * `release_date` (year, MinMaxâ€‘normalized)
   * **Processing**: Ordinal or oneâ€‘hot encode genre + scale date â†’ small MLP
   * **Output**: \~8â€‘dim vector

4. **Fusion Layer**

   * **Operation**: Concatenate `[lyrics_vector â€– audio_vector â€– metadata_vector]` â†’ combined dim \~ (1024 + 22 + 8)
   * **Role**: Merge modalities into a single feature vector

5. **MLP â€“ Feature Projection**

   * **Purpose**: Project the highâ€‘dim fused vector to a compact embedding (e.g., 512â€‘d)
   * **Structure**: One or two Dense layers with nonâ€‘linearities and dropout

6. **Encoder Network**

   * **Purpose**: Further transform the pooled embedding via fully connected layers
   * **Output**: Final shared representation used by both regression head and similarity search

7. **Regression Head**

   * **Output neurons**: 18 continuous targets

     ```
     dating, violence, world/life, night/time, shake the audience,
     family/gospel, romantic, communication, obscene, music,
     movement/places, light/visual perceptions, family/spiritual,
     like/girls, sadness, feelings, danceability
     ```
   * **Loss**: Mean Squared Error (MSE) or Huber loss

---

## âš™ï¸ Data Flow & Training

1. **Precompute** audio features for each song and store alongside lyrics and metadata.
2. **During each training step**:

   * Tokenize & encode lyrics via `bge-large-en-v1.5`.
   * Normalize & project audio and metadata through their MLP encoders.
   * Fuse, project, encode, and predict all 18 labels.
3. **Endâ€‘toâ€‘end fineâ€‘tuning** includes the LLM weights (via LoRA/adapters for efficiency).

---

## ðŸš§ Future Extensions

* **Architecture tweaks**: depth/width of MLPs, alternative fusion strategies.
* **Additional modalities**: cover art embeddings, user interaction signals.
* **Multiâ€‘task learning**: auxiliary genre or era classification tasks.

---

> *This documentation may be updated as the system evolves.*
